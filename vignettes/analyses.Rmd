---
title: "COVID-19 Stuff"
author: "My Heart Fitness"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


#### Basic questions:
* Seek the patients' perspectives around the importance of exercising during pandemic.
* Would also like to know whether they perceive their physicians to prioritize exercise and lifestyle behaviours any less importantly than they otherwise might, during this pandemic.

#### Variables and interactions of interest:
1. MET minutes
1. Volume of visits
1. Attendance
1. % Attendance and Met-minute interactions (because it is a sign of compliance)
1. Mean age and % females.

Use a time series analysis. We should do some p values using time series comparing pre-post trends around the week of march 16th within each year. We also want to compare time trends in 2020 vs 2019 statistically.

## Fitting a model to 2020 MET-Met-Minutes.

We'll start by using `read_data()` to create the dataset we're going to use and properly format/type the attributes. This is more an exercise in data wrangling than anything else.
We need to ascertain the model we're going to be using, and learn about the data and its features. The data runs from Jan 1 2019 until April 31 2019 and Jan 1 2019 until April 31, 2020. We begin by asking if the time series for 2019 and 2020 are stationary. Let's start with a visual inspection. We'll plot the variable against time. For *MET-minutes*, our plots for 2019 and 2020 are below.

```{r fig.width = 5, fig.height = 5}
# Met-minutes in 2019
plot(ts(RMHF::read_data()[1:11,"Met-minutes"]))
#  Met minutes in 2020
plot(ts(RMHF::read_data()[12:22,"Met-minutes"]))
```

_We also note that there is no consistent trend in either time series over the entire time span. The series appear to wander up and down. There also don't appear to be any obvious outliers in either time series._

Let's create some more specific data:

```{r}
df <- RMHF::read_data()
df2019mets <- df[1:11, "Met-minutes"]
tsdf2019mets <- ts(df2019mets)
# Is the 2020 time-series stationary?
df2020mets <- df[12:22, "Met-minutes"]
tsdf2020mets <- ts(df2020mets)
```

First, let's use two tests of stationarity (Augmented Dickey-Fuller, KPSS) to determine whether the time series is stationary. Let's start with the Augmented-Dickey-Fuller test. Here, the null hypothesis is that the series is non-stationary, that is, the existence of a unit root. The alternative hypothesis is that the series is stationary. We'd like a p value less than 0.05 to reject the null.

```{r}
df <- RMHF::read_data()
# Is the 2019 time-series stationary?
tseries::adf.test(tsdf2019mets, alternative = "stationary")
# Is the 2020 time-series stationary?
tseries::adf.test(tsdf2020mets, alternative = "stationary")
```

Alright, so the Augmented Dickey-Fuller test tells us we can't reject the null hypothesis that the series is non-stationary in either 2019 or 2020. This is important for us. Given that we have non-stationary data, we will need to “difference” the data until we obtain a stationary time series. We'll start with the “first-order"" difference. What we're doing here is that is removing the previous Y _met-minutes_ values only once.  For each time point in our data, this gives you the change in value from the previous time point. So let's do this in parallel for 2019 and 2020.

```{r}
# Differencing 2019 data and comparing the result.
arima(tsdf2019mets, order = c(0,0,0))
tsdf2019mets_diff1<- diff(tsdf2019mets, differences = 1)
tseries::adf.test(tsdf2019mets_diff1, alternative = "stationary")
arima(tsdf2019mets, order = c(0,1,0))

# Differencing 2020 data and comparing the result.
arima(tsdf2020mets, order = c(0,0,0))
tsdf2020mets_diff1 <- diff(tsdf2020mets, differences = 1)
tseries::adf.test(tsdf2020mets_diff1, alternative = "stationary")
arima(tsdf2020mets, order = c(0,1,0))
```

*Understanding our results*
Differencing the first time didn't make either time series stationary. But the standard deviation increased in both cases which indicates overdifferencing. In addition, the kpss test shows that both series were stationary from the get-go.

```{r}
tseries::kpss.test(tsdf2019mets)
tseries::kpss.test(tsdf2020mets)
```

Because differencing appears to worsen the model fit in the best case, and in the worst case we don't need it, let's assume the time series are stationary. auto.arima in R uses the results from the kpss test over those from the adf test by default anyway. So let's assume they are.

Now we should check if the time series are seasonal. Let's check for patterns or regularity in the autocorrelograms and partialcorrelograms. If there is a pattern are, we should extract its frequency from both time series. As a quick refresher, p refers to how many previous (lagged) *Y* values are accounted for at each point, and q refers to how many previous (lagged) *error* values are accounted for each time point in our model.

A correlogram plot of the correlation of each MET-minute variable at time t with that at time t-k. A partial correlogram the same except for the fact that it removes the effect of shorter autocorrelation lags when calculating the correlation at longer lags. Techhnically speaking, the partial correlation at lag k is the autocorrelation between Yt and Yt-k that is NOT accounted for by the autocorrelations from the 1st to the (k-1)st lags.

Let's explore the correlogram and partial correlograms for the 2019 and 2020 data, respectively.
```{r fig.height = 4, fig.width = 4}
acf(as.numeric(tsdf2019mets))
pacf(as.numeric(tsdf2019mets))

acf(as.numeric(tsdf2020mets))
pacf(as.numeric(tsdf2020mets))

```

The 0th lag will always be significant but this tells us nothing. What we do see is a lack of a pattern in both the acf and pacf for both plots. This points to a lack of seasonality. Indeed, if we try and extract the frequency from both objects. we obtain one, indicating no seasonality.

```{r}
#Extract frequency from 2019 data.
forecast::findfrequency(tsdf2019mets)
#Extract frequency from 2020 data.
forecast::findfrequency(tsdf2020mets)
```
This agrees with *"Wiener–Khinchin theorem, also known as the Wiener–Khintchine theorem and sometimes as the Wiener–Khinchin–Einstein theorem or the Khinchin–Kolmogorov theorem, [which] states that the autocorrelation function of a wide-sense-stationary random process has a spectral decomposition given by the power spectrum of that process"* (Wikipedia).

But what if we were to decompose each year by seasonal periods of 2, 3, 4, or 5 weeks (the maximum for a series of 11 points to be periodic)? Seastest does exactly this by using an F test on seasonal dummies and checking for statistically significant seasonality coefficients (betas).

```{r}
testSeasonality <- function(listobj){
  possibleFreqs <- 2:5
  for (thefreq in possibleFreqs){
    print(paste0("Is seasonal at a frequency of: ", thefreq, " ?" ))
    print(seastests::isSeasonal(ts(listobj), freq = thefreq, test = "seasdum"))
  }
}
#Try 2019.
testSeasonality(df2019mets)
#Try 2020.
testSeasonality(df2020mets)
```

We've now concluded that neither time series is seasonal, and that both are stationary (to the extent that differencing worsens the model fit, which auto.arima() also agrees with). Now that we have a stationary time series for each year, we should fit the appropriate nonseasonal ARIMA model. This means finding the most appropriate values for *p* and *q*, as *d = 0*, for both models.

The largest statistically significant lag values of the correlogram gives the possible *q* values for the ARIMA model. In addition, the largest statistically significant lag of the partial correlogram gives the *p* value for an ARIMA model. Looking back at our ACF and PACFs above, we note the folloiwng possible models for 2019 and 2020, respectively.

*Possible ARIMA models*
1. 2019: (p,d,q) = (0,0,0), 
1. 2020: (p,d,q) = (0,0,0), 

There are no autoregressive or moving average terms required here. We're left with a white noise model. This indicates that linear regression may be more appropriate here.

Let's fit the two white noise models and a linear regression as well.

```{r}
#Fit both ARIMA models.
arima2019 <- forecast::Arima(tsdf2019mets)
arima2020 <- forecast::Arima(tsdf2020mets)

df2019 <- df[1:11, ]
df2020 <- df[12:22, ]
#Fix the column names of both objects so we can fit the regression models.
colnames(df2019) <- c(colnames(df2019)[1:10], "mets")
colnames(df2020) <- c(colnames(df2020)[1:10], "mets")
#Properly type the met-minutes column of each dataset.
df2019$mets <- as.numeric(df2019$mets)
df2020$mets <- as.numeric(df2020$mets)
#Add a week number column to both datasets to regress on time.
df2019$weekNum <- 1:11
df2020$weekNum <- 1:11
#Fit the regression models!
lm2019 <- lm(df2019, formula = mets ~ weekNum)
lm2020 <- lm(df2020, formula =  mets ~ weekNum)
```

Time to check our work. The Ljung-Box statistic tests the null hypothesis that the residuals are distributed independently _(H0)_, vs the _(Ha)_ hypothesis that the residuals exhbit some form of autocorrelation (the model shows lack of fit). In other words, if the p value is greater than 0.05 then the residuals are independent. We want p > 0.05.

```{r fig.width = 5}
#Check 2019 ARIMA.
forecast::checkresiduals(arima2019)
forecast::checkresiduals(forecast::auto.arima(tsdf2019mets))

#Check 2020 ARIMA.
forecast::checkresiduals(arima2020)
forecast::checkresiduals(forecast::auto.arima(tsdf2020mets))
```

These work!

```{r}
#Check 2019 linear regression.
forecast::checkresiduals(lm2019)
#Check 2020 linear regression.
forecast::checkresiduals(lm2020)
```

We don't want to reject the null in the Breusch-Godfrey test, as it's that there's no serial correlation in our data. In other words, we want p > 0.05 for this to work.

# 2020 COVID-19 Intervention Analysis

Our intervention analyses will follow the structure below (taken from https://online.stat.psu.edu/stat510/lesson/9/9.2):

1. Use the data before the intervention point (March 16, 2020) to determine the ARIMA model that we'l be using.
1. Use that ARIMA model to forecast values for the period after the intervention date.
1. Calculate the differences between actual values after the intervention and the forecasted values
1. Examine the differences to determine a model for the intervention effect.

##MET minutes
If we fit an ARIMA model to the 2020 [Jan 1 - March11] data automatically, we yield the following automatic model fit.
```{r}
autofit <- forecast::auto.arima(ts(RMHF::read_data()[11:16, "Met-minutes"]))
```

Checking our assumptions.

```{r fig.height = 5, fig.width = 5}
forecast::checkresiduals(autofit)
tsdiag(autofit)
```

All the autocorrelations for the residual series are non-significant, which is what we'd like. The model passes the Box-Ljung test as well. In other words, our model appears to work. Let's use it to forecast the five values after March 16th, 2020 that we have in our original time series.

```{r}
pred <- forecast::forecast(autofit)
print(pred)
```

##Volume of visits
```{r}
df <- RMHF::read_data()
df2019volume <- df[1:11, "Prescheduled appointments"]
ts2019volume <- ts(df2019volume)
df2020volume <- df[12:22, "Prescheduled appointments"]
ts2020volume <- ts(df2020volume)
```

##Attendance
```{r}
df <- RMHF::read_data()
df2019noshows <- df[1:11, "% of patients who were no-shows"]
ts2019noshows <- ts(df2019noshows)
df2020nowshows <- df[12:22, "% of patients who were no-shows"]
ts2020noshows <- ts(df2020nowshows)
```

##Interactions

*% Attendance and Met-minute interactions (because it is a sign of compliance)*
```{r}
```


*Mean age and % females*
```{r}
df <- RMHF::read_data()
```
